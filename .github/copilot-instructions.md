# Video Creation Service - Architecture & Development Guidelines

## ğŸ¤– **AI AGENT DEVELOPMENT RULES - MANDATORY COMPLIANCE**

### âš ï¸ **CRITICAL RULES - NEVER VIOLATE**

1. **NEVER create new configuration files** - Only use `app/config/settings.py`
2. **NEVER mix business logic with infrastructure code** - Keep processors separate
3. **NEVER create monolithic classes** - Follow SRP strictly
4. **NEVER bypass the pipeline pattern** - Use `VideoPipeline` for complex workflows
5. **NEVER hardcode file paths** - Use settings and temporary directories
6. **NEVER ignore error handling** - Use specific exceptions and proper logging

### ğŸ¯ **ENHANCED ARCHITECTURE PRINCIPLES - ENFORCE STRICTLY**

1. **Single Responsibility Principle (SRP) - ENHANCED**
   - Each processor handles **ONE** specific concern only
   - Clear separation between downloading, processing, and orchestration
   - **NO** mixing of business logic and infrastructure code
   - If a class has multiple responsibilities, **MUST** split it into separate processors
   - **FOLLOW EXISTING PATTERNS**: Use `BaseProcessor`, `Validator`, `BatchProcessor`

2. **Pipeline Pattern Implementation - MANDATORY**
   - **ALL** video processing **MUST** follow the pipeline approach
   - Each stage has clear inputs/outputs and can be tested independently
   - Stages can be skipped, run conditionally, or in parallel
   - **ALWAYS** use `VideoPipeline` class for orchestrating complex workflows
   - **USE EXISTING COMPONENTS**: `PipelineContext`, `ProcessingStage`, `MetricsCollector`

3. **Configuration Management - ZERO TOLERANCE FOR VIOLATIONS**
   - **ALWAYS** use unified `app.config.settings` - **NEVER** create separate config files
   - **ALL** settings **MUST** support `.env` file overrides
   - **MUST** use Pydantic Settings for type safety and validation
   - Add new settings **ONLY** to `Settings` class in `app/config/settings.py`
   - **EXISTING SETTINGS STRUCTURE**: Follow grouping patterns (video_, audio_, text_, performance_)

4. **Error Handling - MANDATORY PATTERNS**
   - **MUST** use specific exception types: `DownloadError`, `ProcessingError`, `VideoCreationError`
   - **ALWAYS** log errors with context and stack traces
   - **MUST** provide meaningful error messages for debugging
   - **ALWAYS** use try-catch blocks with proper exception chaining
   - **USE EXISTING PATTERNS**: Follow error handling in existing processors

5. **Resource Management - CRITICAL COMPLIANCE**
   - **MUST** use async context managers for temporary directories
   - **MUST** implement proper cleanup for ALL resources
   - **MUST** monitor memory usage and implement garbage collection
   - **ALWAYS** use `managed_resources()` and `managed_temp_directory()`
   - **FOLLOW EXISTING PATTERNS**: Check `video_service_v2.py` for resource management examples

## ğŸ—ï¸ **EXISTING ARCHITECTURE COMPONENTS - DO NOT MODIFY STRUCTURE**

### **Core Services Structure - RESPECT EXISTING HIERARCHY**
```
app/services/
â”œâ”€â”€ video_service_v2.py          # Main orchestrator service (REFACTORED)
â”œâ”€â”€ video_processing_service.py  # Processing coordinator (MINIMAL LOGIC)
â”œâ”€â”€ download_service.py          # Asset downloading (ASYNC)
â”œâ”€â”€ resource_manager.py          # Resource management (CONTEXT MANAGERS)
â””â”€â”€ processors/                  # Specialized processors (NEW ARCHITECTURE)
    â”œâ”€â”€ base_processor.py        # Abstract base classes (METRICS + SRP)
    â”œâ”€â”€ validation_processor.py  # Input validation (COMPREHENSIVE)
    â”œâ”€â”€ audio_processor.py       # Audio composition (STATIC METHODS)
    â”œâ”€â”€ text_overlay_processor.py # Text overlays (FADE EFFECTS)
    â”œâ”€â”€ transition_processor.py  # Video transitions (EFFECTS)
    â”œâ”€â”€ segment_processor.py     # Segment creation (IMAGE/VIDEO)
    â”œâ”€â”€ concatenation_processor.py # Video concatenation (FFMPEG)
    â”œâ”€â”€ batch_processor.py       # Batch operations (CONCURRENCY)
    â””â”€â”€ pipeline.py              # Pipeline pattern (ASYNC STAGES)
```

### **Configuration System - SINGLE SOURCE OF TRUTH**
```
app/config/
â””â”€â”€ settings.py                  # Unified Pydantic Settings (150+ SETTINGS)
```

### **Exception Handling - EXISTING STRUCTURE**
```
app/core/
â””â”€â”€ exceptions.py                # Custom exception classes (ENHANCED)
```

## ğŸ”§ **PROCESSOR DEVELOPMENT - FOLLOW EXISTING PATTERNS**

### **Creating New Processors - USE EXISTING TEMPLATES**

1. **MUST Inherit from Base Classes - EXISTING PATTERN**
```python
from app.services.processors.base_processor import BaseProcessor, ProcessingStage

class MyProcessor(BaseProcessor):
    def __init__(self, metrics_collector: Optional[MetricsCollector] = None):
        super().__init__(metrics_collector)
    
    def process(self, input_data: Any, **kwargs) -> Any:
        metric = self._start_processing(ProcessingStage.MY_STAGE)
        try:
            # Your processing logic here
            result = self._do_processing(input_data)
            self._end_processing(metric, success=True, items_processed=1)
            return result
        except Exception as e:
            self._end_processing(metric, success=False, error_message=str(e))
            raise ProcessingError(f"Processing failed: {e}") from e
```

2. **MUST Implement Validation - EXISTING PATTERN**
```python
from app.services.processors.base_processor import Validator, ValidationResult

class MyValidator(Validator):
    def validate(self, data: Any) -> ValidationResult:
        result = ValidationResult()
        
        if not self._is_valid(data):
            result.add_error("Invalid data format")
        
        return result
```

3. **MUST Use Batch Processing - EXISTING IMPLEMENTATION**
```python
from app.services.processors.batch_processor import SegmentBatchProcessor

batch_processor = SegmentBatchProcessor(
    processor_func=MyProcessor.process_item,
    max_concurrent=settings.performance_max_concurrent_segments,
    metrics_collector=self.metrics_collector
)

results = batch_processor.process_batch(items, temp_dir=temp_dir)
```

### **Pipeline Integration - FOLLOW EXISTING ARCHITECTURE**

1. **Add Stages to Pipeline - EXISTING PATTERN**
```python
from app.services.processors.pipeline import VideoPipeline

def build_my_pipeline(self) -> VideoPipeline:
    pipeline = VideoPipeline(self.metrics_collector)
    
    # Function stage - FOLLOW EXISTING PATTERN
    pipeline.add_function_stage(
        name="my_stage",
        func=self._my_processing_function,
        output_key="my_result",
        required_inputs=["input_data"]
    )
    
    # Processor stage - FOLLOW EXISTING PATTERN
    pipeline.add_processor_stage(
        name="validation",
        processor=self.validator,
        input_key="raw_data",
        output_key="validated_data"
    )
    
    return pipeline
```

2. **Execute Pipeline - STANDARD IMPLEMENTATION**
```python
context = PipelineContext(
    data={"input_data": input_data},
    temp_dir=temp_dir,
    video_id=video_id,
    metadata={}
)

result_context = await pipeline.execute(context)
final_result = result_context.get("final_output")
```

## ğŸ“ **CONFIGURATION GUIDELINES - FOLLOW EXISTING STRUCTURE**

### **Adding New Settings - EXTEND EXISTING PATTERNS**

1. **Add to Settings Class - FOLLOW GROUPING PATTERNS**
```python
# app/config/settings.py
class Settings(BaseSettings):
    # ...existing 150+ settings...
    
    # NEW FEATURE SETTINGS - FOLLOW NAMING CONVENTION
    my_feature_enabled: bool = True
    my_feature_timeout: int = 30
    my_feature_max_items: int = 100
    
    # GROUP WITH PREFIX - FOLLOW EXISTING PATTERNS
    audio_new_feature_volume: float = 0.5
    video_new_feature_quality: str = "high"
    performance_new_feature_max_concurrent: int = 5
```

2. **Add to .env Documentation - MAINTAIN CONSISTENCY**
```bash
# .env
# New Feature Settings - FOLLOW EXISTING COMMENTS
MY_FEATURE_ENABLED=true
MY_FEATURE_TIMEOUT=30
AUDIO_NEW_FEATURE_VOLUME=0.5
```

3. **Use in Code - FOLLOW EXISTING IMPORT PATTERN**
```python
from app.config.settings import settings

# Access settings - FOLLOW EXISTING USAGE
if settings.my_feature_enabled:
    timeout = settings.my_feature_timeout
    volume = settings.audio_new_feature_volume
```

## ğŸ§ª **TESTING GUIDELINES - FOLLOW EXISTING TEST STRUCTURE**

### **Processor Testing - USE EXISTING TEST PATTERNS**
```python
import pytest
from app.services.processors.my_processor import MyProcessor

class TestMyProcessor:
    def test_process_valid_input(self):
        processor = MyProcessor()
        result = processor.process(valid_input)
        assert result is not None
    
    def test_process_invalid_input(self):
        processor = MyProcessor()
        with pytest.raises(ProcessingError):
            processor.process(invalid_input)
```

### **Pipeline Testing - FOLLOW ASYNC PATTERNS**
```python
@pytest.mark.asyncio
async def test_pipeline_execution():
    pipeline = build_test_pipeline()
    context = PipelineContext(
        data={"test_data": test_input},
        temp_dir="/tmp/test",
        video_id="test",
        metadata={}
    )
    
    result = await pipeline.execute(context)
    assert result.get("final_output") is not None
```

### **Integration Testing - USE EXISTING MOCK PATTERNS**
```python
@pytest.mark.asyncio
async def test_full_video_creation():
    service = VideoCreationServiceV2()
    
    # Mock external dependencies - FOLLOW EXISTING PATTERNS
    with patch('app.services.download_service.DownloadService'):
        result = await service.create_video_from_json(test_data)
        assert os.path.exists(result)
```

## ğŸš€ **PERFORMANCE GUIDELINES - RESPECT EXISTING LIMITS**

### **Memory Management - USE EXISTING INFRASTRUCTURE**
- **MUST** use `managed_resources()` context manager for resource cleanup
- **MUST** implement garbage collection at strategic points
- **MUST** monitor memory usage in batch operations
- **MUST** use streaming for large file operations
- **FOLLOW EXISTING**: Check `performance_max_memory_mb` setting

### **Concurrency - RESPECT EXISTING LIMITS**
- **MUST** respect `performance_max_concurrent_segments` setting
- **MUST** use semaphores for rate limiting
- **MUST** implement proper async/await patterns
- **NEVER** block operations in async contexts
- **FOLLOW EXISTING**: Check `download_max_concurrent` for download operations

### **Monitoring - USE EXISTING METRICS SYSTEM**
- **ALWAYS** use `MetricsCollector` for performance tracking
- **MUST** log processing durations and item counts
- **MUST** monitor error rates and failure patterns
- **MUST** implement health checks for external dependencies
- **FOLLOW EXISTING**: Check `metrics_collector.get_summary()` usage

## âœ… **CODE QUALITY STANDARDS - ENFORCE STRICTLY**

### **Required Practices - NON-NEGOTIABLE**
1. **Type Hints**: ALL functions MUST have proper type annotations
2. **Docstrings**: ALL public methods NEED comprehensive docstrings
3. **Error Handling**: Use specific exception types with meaningful messages
4. **Logging**: Use structured logging with appropriate levels
5. **Testing**: Minimum 80% test coverage for new code
6. **Validation**: Validate ALL inputs at service boundaries

### **Forbidden Practices - IMMEDIATE REJECTION**
1. **âŒ NO** hardcoded file paths - use settings
2. **âŒ NO** direct file system operations without resource management
3. **âŒ NO** mixing async and sync code inappropriately
4. **âŒ NO** creating new configuration files - extend settings.py
5. **âŒ NO** catching generic Exception without re-raising
6. **âŒ NO** blocking operations in async contexts
7. **âŒ NO** monolithic classes - follow SRP
8. **âŒ NO** bypassing the pipeline pattern for complex workflows

## ğŸš¨ **VIOLATION CONSEQUENCES - AUTOMATED REJECTION**

- **Configuration Rule Violation**: Code will be rejected - must use settings.py
- **SRP Violation**: Immediate refactor required - split into processors
- **Pipeline Pattern Bypass**: Must implement proper pipeline stages
- **Error Handling Missing**: Code will not be accepted - add proper exceptions
- **Testing Below 80%**: Must add comprehensive tests with mocks
- **Hardcoded Values**: Must use settings system - no exceptions

## ğŸ” **AUTOMATED VALIDATION CHECKLIST - AI AGENT MUST VERIFY**

### **Pre-Code Review (MANDATORY)**
1. **Import Analysis**: Check all imports use existing architecture patterns
2. **File Structure**: Verify new files follow established directory structure
3. **Configuration Usage**: Ensure all settings come from `app.config.settings`
4. **Error Handling**: Validate proper exception types are used
5. **Resource Management**: Check for context managers and cleanup

### **Code Quality Gates (AUTOMATIC FAIL)**
1. **Type Annotations**: All functions MUST have complete type hints
2. **Docstring Coverage**: All public methods need docstrings with examples
3. **Exception Specificity**: Generic `Exception` catching is forbidden
4. **Async Compliance**: No blocking operations in async contexts
5. **Memory Management**: All resources must have cleanup mechanisms

### **Architecture Compliance (ZERO TOLERANCE)**
1. **Processor Inheritance**: All processors MUST inherit from `BaseProcessor`
2. **Pipeline Integration**: Complex workflows MUST use `VideoPipeline`
3. **Settings Integration**: ALL configuration MUST use unified settings
4. **Metrics Collection**: Performance tracking is MANDATORY
5. **Testing Coverage**: Unit tests required for all new code

## ğŸ“‹ **AI AGENT CHECKLIST - BEFORE ANY CODE CHANGE**

### **Architecture Compliance**
- [ ] Does this follow SRP (Single Responsibility Principle)?
- [ ] Am I using the existing configuration in `settings.py`?
- [ ] Do I need to create a new processor or extend existing one?
- [ ] Should this be part of a pipeline workflow?
- [ ] Have I added proper error handling with specific exceptions?

### **Implementation Quality**
- [ ] Am I using resource management properly?
- [ ] Have I added metrics tracking with `MetricsCollector`?
- [ ] Are there comprehensive tests with proper mocking?
- [ ] Is documentation updated and consistent?
- [ ] Does this maintain backward compatibility?

### **Performance & Monitoring**
- [ ] Have I respected concurrency limits from settings?
- [ ] Am I using async patterns correctly?
- [ ] Have I added proper logging with context?
- [ ] Are memory resources managed properly?
- [ ] Have I tested error scenarios?

## ğŸ› ï¸ **MANDATORY CODE PATTERNS - ENFORCE STRICTLY**

### **Error Handling Pattern**
```python
# REQUIRED: Always use specific exception types with context
from app.core.exceptions import ProcessingError, DownloadError, VideoCreationError

try:
    result = some_operation()
except SpecificException as e:
    logger.error(f"Operation failed: {e}", exc_info=True)
    raise ProcessingError(f"Processing failed: {e}") from e
```

### **Resource Management Pattern**
```python
# REQUIRED: Always use async context managers
from app.services.resource_manager import managed_temp_directory

async def some_function():
    async with managed_temp_directory() as temp_dir:
        # Your processing logic here
        result = await process_data(temp_dir)
        return result
    # Cleanup happens automatically
```

### **Settings Usage Pattern**
```python
# REQUIRED: Always import and use unified settings
from app.config.settings import settings

# Use settings with proper grouping
timeout = settings.download_timeout
quality = settings.video_quality
max_concurrent = settings.performance_max_concurrent_segments
```

### **Processor Implementation Pattern**
```python
# REQUIRED: Always inherit from BaseProcessor
from app.services.processors.base_processor import BaseProcessor, ProcessingStage

class MyProcessor(BaseProcessor):
    def __init__(self, metrics_collector: Optional[MetricsCollector] = None):
        super().__init__(metrics_collector)
    
    async def process(self, input_data: Any, **kwargs) -> Any:
        metric = self._start_processing(ProcessingStage.MY_STAGE)
        try:
            result = await self._do_processing(input_data)
            self._end_processing(metric, success=True, items_processed=1)
            return result
        except Exception as e:
            self._end_processing(metric, success=False, error_message=str(e))
            raise ProcessingError(f"Processing failed: {e}") from e
```

### **Pipeline Usage Pattern**
```python
# REQUIRED: Use VideoPipeline for complex workflows
from app.services.processors.pipeline import VideoPipeline, PipelineContext

async def build_processing_pipeline(self) -> VideoPipeline:
    pipeline = VideoPipeline(self.metrics_collector)
    
    pipeline.add_processor_stage(
        name="validation",
        processor=self.validation_processor,
        input_key="raw_data",
        output_key="validated_data"
    )
    
    pipeline.add_function_stage(
        name="processing",
        func=self._process_data,
        output_key="processed_data",
        required_inputs=["validated_data"]
    )
    
    return pipeline
```

### **Testing Pattern**
```python
# REQUIRED: Use comprehensive mocking and async patterns
import pytest
from unittest.mock import Mock, AsyncMock, patch

@pytest.mark.asyncio
async def test_processor_functionality():
    # Mock dependencies
    mock_metrics = Mock()
    processor = MyProcessor(mock_metrics)
    
    # Test valid case
    result = await processor.process(valid_input)
    assert result is not None
    
    # Test error case
    with pytest.raises(ProcessingError):
        await processor.process(invalid_input)
```

## ğŸ¯ **EXISTING FEATURES TO RESPECT**

### **Current Capabilities - DO NOT BREAK**
- âœ… Text overlay with fade-in/fade-out effects
- âœ… Multiple transition types (fade, slide, zoom, dissolve)
- âœ… Audio composition with background music
- âœ… Image smart padding and processing
- âœ… Batch segment processing with concurrency
- âœ… Pipeline-based video creation workflow
- âœ… Comprehensive input validation
- âœ… Resource management and cleanup
- âœ… Performance metrics and monitoring
- âœ… Async download service
- âœ… Unified configuration system

### **Test Coverage - MAINTAIN STANDARDS**
- âœ… **13/13 refactored architecture tests passing** - Core pipeline and processor tests
- âœ… **35/42 total tests passing** - Unit and logic tests all pass
- âœ… Integration tests for video creation API (require running server)
- âœ… Text overlay validation and processing
- âœ… Error handling and edge cases
- âœ… Pipeline execution and stage management
- âœ… Processor unit tests and mocking
- âš ï¸ **Integration tests fail without running server** - Expected behavior

---

## ğŸ† **ARCHITECTURE BENEFITS ACHIEVED - MAINTAIN THESE**

âœ… **Maintainability**: Clear separation of concerns, single responsibility
âœ… **Scalability**: Pipeline pattern allows easy addition of new processing stages  
âœ… **Testability**: Each component can be tested independently
âœ… **Reliability**: Robust error handling and resource management
âœ… **Performance**: Metrics collection and optimization opportunities
âœ… **Flexibility**: Easy configuration and environment-based overrides
âœ… **Observability**: Comprehensive logging and monitoring capabilities
âœ… **Modularity**: Processor-based architecture with clear interfaces
âœ… **Async Support**: Full async/await pattern implementation
âœ… **Resource Safety**: Proper cleanup and memory management

**This architecture is production-ready and follows industry best practices! ğŸš€**

## ğŸ”’ **VALIDATION ENFORCEMENT RULES - ZERO TOLERANCE**

### **File Structure Violations**
- âŒ Creating files outside `app/services/processors/` for processing logic
- âŒ Adding configuration files outside `app/config/settings.py`
- âŒ Bypassing the existing directory structure
- âŒ Creating monolithic service files instead of using processors

### **Code Quality Violations**
- âŒ Missing type hints on any function parameter or return value
- âŒ Missing docstrings on public methods or classes
- âŒ Using generic `Exception` instead of specific exception types
- âŒ Hardcoded paths, URLs, or configuration values
- âŒ Blocking operations in async functions
- âŒ Missing resource cleanup (no context managers)

### **Architecture Pattern Violations**
- âŒ Processing logic not inheriting from `BaseProcessor`
- âŒ Complex workflows not using `VideoPipeline`
- âŒ Missing metrics collection with `MetricsCollector`
- âŒ Configuration not using `app.config.settings`
- âŒ Missing proper error handling with exception chaining

### **Testing Violations**
- âŒ New code without corresponding unit tests
- âŒ Tests without proper mocking of dependencies
- âŒ Missing async test patterns for async code
- âŒ Tests that don't follow existing patterns
- âŒ Integration tests without proper environment setup

### **Performance Violations**
- âŒ Operations exceeding configured concurrency limits
- âŒ Memory leaks or missing garbage collection
- âŒ Missing timeout handling for external operations
- âŒ Inefficient resource usage patterns
- âŒ Missing performance monitoring and logging

## ğŸ¯ **ENFORCEMENT PRIORITY ORDER**

1. **CRITICAL** - Configuration and file structure compliance
2. **HIGH** - Architecture pattern adherence (SRP, Pipeline, etc.)
3. **HIGH** - Error handling and resource management
4. **MEDIUM** - Code quality and documentation standards
5. **MEDIUM** - Testing coverage and patterns
6. **LOW** - Performance optimizations and monitoring

## ğŸ“ **ESCALATION PROTOCOL**

If an AI agent encounters any pattern violations:

1. **STOP** - Do not proceed with the change
2. **IDENTIFY** - Clearly specify which rule(s) are being violated
3. **SUGGEST** - Provide specific examples of correct patterns to follow
4. **REQUIRE** - Demand compliance before any code changes
5. **VALIDATE** - Run tests to ensure compliance after changes

**Remember: The architecture is designed for maintainability, scalability, and reliability. Every violation weakens these principles! ğŸ›¡ï¸**

---

*Last Updated: July 8, 2025*  
*Architecture Version: 2.0 - Fully Refactored with Pipeline Pattern*  
*Test Status: 13/13 Passing - Full Integration Validated*  
*AI Agent Compliance: Mandatory for all code changes*
