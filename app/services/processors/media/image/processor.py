"""
ImageAutoProcessor: Ki·ªÉm tra v√† t·ª± ƒë·ªông thay th·∫ø ·∫£nh cho segment n·∫øu ·∫£nh kh√¥ng h·ª£p l·ªá.
- S·ª≠ d·ª•ng PydanticAI ƒë·ªÉ tr√≠ch xu·∫•t keywords th√¥ng minh t·ª´ segment text v·ªõi type safety.
- N·∫øu ·∫£nh kh√¥ng ph√π h·ª£p, t·ª± ƒë·ªông t√¨m ki·∫øm ·∫£nh m·ªõi (Pixabay API v·ªõi AI-enhanced keywords).
"""

import asyncio
import logging
import os
import shutil
from pathlib import Path
from typing import Any, List, Optional, Tuple
from uuid import uuid4

import requests
from pydantic import BaseModel
from pydantic_ai import Agent
from pydantic_ai.models.openai import OpenAIModel

from app.config.settings import settings
from app.core.exceptions import ProcessingError
from app.services.processors.core.base_processor import AsyncProcessor, ProcessingStage
from utils.image_utils import is_image_size_valid, search_pixabay_image

logger = logging.getLogger(__name__)


class KeywordExtractionResult(BaseModel):
    """Structured result for AI keyword extraction"""

    keywords: List[str] = []


class ImageProcessor(AsyncProcessor):
    """
    AI-powered image validation and replacement processor using PydanticAI.
    """

    def __init__(self):
        super().__init__()
        # Lu√¥n d√πng tr·ª±c ti·∫øp settings.openai_api_key
        self.ai_api_key = settings.openai_api_key

        # Initialize PydanticAI Agent
        self._init_ai_agent()

    def _init_ai_agent(self):
        """Initialize PydanticAI Agent for keyword extraction"""
        if self.ai_api_key and settings.ai_keyword_extraction_enabled:
            try:
                # Create OpenAI model instance (PydanticAI s·∫Ω t·ª± ƒë·ªông d√πng OPENAI_API_KEY t·ª´ env)
                model = OpenAIModel(model_name=settings.ai_pydantic_model)

                # Create PydanticAI Agent with structured output
                self.keyword_agent = Agent(
                    model=model,
                    result_type=KeywordExtractionResult,
                    system_prompt="""You are a smart keyword-extraction assistant for image search.

                        Your task: Extract 4-8 multi-word search phrases that are optimized for Pixabay image search.

                        Requirements:
                        ‚Ä¢ Generate compound keywords (2-4 words each)
                        ‚Ä¢ Focus on visual, descriptive terms
                        ‚Ä¢ Avoid generic single words
                        ‚Ä¢ Prioritize searchable, relevant phrases
                        ‚Ä¢ Use clear, descriptive language

                        Return structured data with:
                        - keywords: List of 4-8 multi-word search phrases
                        - primary_keyword: Most important keyword
                        - search_strategy: "progressive"

                        Example:
                        Input: "AI Agents will revolutionize technology by 2025"
                        Output: keywords=["futuristic AI assistant", "autonomous technology concept", "digital agent illustration", "AI revolution 2025"]
                        """,
                )
                logger.info("ü§ñ PydanticAI Agent initialized successfully")
            except (ImportError, ValueError, RuntimeError) as e:
                logger.warning("Failed to initialize PydanticAI Agent: %s", str(e))
                self.keyword_agent = None
        else:
            self.keyword_agent = None

    async def _ai_extract_keywords(
        self, content: str, fields: Optional[List[str]] = None
    ) -> List[str]:
        """
        D√πng PydanticAI ƒë·ªÉ tr√≠ch xu·∫•t t·ª´ kh√≥a t√¨m ki·∫øm th√¥ng minh t·ª´ content v√† fields.
        Tr·∫£ v·ªÅ list keywords theo ƒë·ªô ∆∞u ti√™n cao ‚Üí th·∫•p.
        """
        # Ki·ªÉm tra setting c√≥ enable AI keyword extraction kh√¥ng
        if not settings.ai_keyword_extraction_enabled or not self.keyword_agent:
            # Fallback: tr√≠ch xu·∫•t t·ª´ kh√≥a ƒë∆°n gi·∫£n
            return fields

        # Chu·∫©n b·ªã prompt cho PydanticAI Agent
        fields = fields or []
        fields_str = ", ".join(fields)
        user_prompt = (
            f"Extract image search keywords from this content: '{content}' "
            f"with these related fields: [{fields_str}]"
        )

        try:
            # S·ª≠ d·ª•ng PydanticAI Agent ƒë·ªÉ extract keywords v·ªõi structured output
            result = await self.keyword_agent.run(user_prompt=user_prompt)

            # Get structured result
            keyword_result: KeywordExtractionResult = result.output

            # Gi·ªõi h·∫°n s·ªë keywords theo setting
            final_keywords = keyword_result.keywords[
                : settings.ai_max_keywords_per_prompt
            ]

            logger.info(
                "ü§ñ PydanticAI extracted keywords: %s from content: '%s' with fields: %s",
                final_keywords,
                content,
                fields,
            )

            return final_keywords

        except (ValueError, TypeError, RuntimeError) as e:
            logger.warning("PydanticAI keyword extraction failed: %s", str(e))
            # Fallback v·ªÅ tr√≠ch xu·∫•t ƒë∆°n gi·∫£n
            return fields

    async def _download_image(
        self,
        content: str,
        fields: List[str],
        temp_dir: str,
    ) -> Tuple[str, str]:
        """
        T√¨m ki·∫øm v√† t·∫£i ·∫£nh m·ªõi.

        Args:
            content: N·ªôi dung ƒë·ªÉ t√¨m ki·∫øm ·∫£nh
            fields: Danh s√°ch c√°c tr∆∞·ªùng t·ª´ kh√≥a
            temp_dir: Th∆∞ m·ª•c t·∫°m ƒë·ªÉ l∆∞u ·∫£nh

        Returns:
            Tuple ch·ª©a (image_url, local_path)

        Raises:
            ProcessingError: N·∫øu c√≥ l·ªói khi t√¨m ki·∫øm ho·∫∑c t·∫£i ·∫£nh
        """
        try:
            # T√¨m ki·∫øm ·∫£nh m·ªõi
            new_url = await self._ai_search_image(
                content=content,
                fields=fields,
                min_width=settings.video_min_image_width,
                min_height=settings.video_min_image_height,
            )
            if not new_url:
                raise ProcessingError(
                    f"Kh√¥ng t√¨m ƒë∆∞·ª£c ·∫£nh ph√π h·ª£p cho content: '{content}' "
                    f"v·ªõi fields: {fields}"
                )

            # T·∫°o t√™n file v√† ƒë∆∞·ªùng d·∫´n m·ªõi
            ext = os.path.splitext(new_url)[1] or ".jpg"
            new_filename = f"auto_image_{uuid4().hex}{ext}"
            save_path = Path(temp_dir) / new_filename

            # T·∫£i ·∫£nh v·ªÅ local
            def download_image(url, path):
                with requests.get(url, stream=True, timeout=10) as r:
                    r.raise_for_status()
                    with open(path, "wb") as f:
                        shutil.copyfileobj(r.raw, f)

            loop = asyncio.get_event_loop()
            await loop.run_in_executor(None, download_image, new_url, str(save_path))

            return new_url, str(save_path)

        except (requests.RequestException, OSError) as e:
            raise ProcessingError(f"Download replacement image failed: {e}") from e

    async def _ai_search_image(
        self,
        content: str,
        fields: Optional[List[str]] = None,
        min_width: Optional[int] = None,
        min_height: Optional[int] = None,
    ) -> Optional[str]:
        """
        AI-enhanced image search:
        - D√πng PydanticAI tr√≠ch xu·∫•t keywords
        - Th·ª≠ nhi·ªÅu keywords v·ªõi Pixabay ƒë·ªÉ t√¨m ·∫£nh ph√π h·ª£p
        """
        pixabay_key = settings.pixabay_api_key
        min_width = min_width or settings.video_min_image_width
        min_height = min_height or settings.video_min_image_height

        # AI tr√≠ch xu·∫•t keywords th√¥ng minh v·ªõi PydanticAI
        keywords_list = await self._ai_extract_keywords(content, fields)

        # Th·ª≠ t·ª´ng keyword cho ƒë·∫øn khi t√¨m ƒë∆∞·ª£c ·∫£nh ph√π h·ª£p
        for keywords in keywords_list:
            url = search_pixabay_image(keywords, pixabay_key, min_width, min_height)
            if url:
                logger.info(
                    "‚úÖ Found image with keywords: %s for content: '%s'",
                    keywords,
                    content,
                )
                return url

        # N·∫øu kh√¥ng t√¨m ƒë∆∞·ª£c g√¨, th·ª≠ keyword fallback cu·ªëi c√πng
        fallback_url = search_pixabay_image(
            "abstract background", pixabay_key, min_width, min_height
        )
        if fallback_url:
            logger.warning("‚ö†Ô∏è Using fallback image for content: '%s'", content)

        return fallback_url

    async def process(self, input_data: Any, **kwargs) -> Any:
        """Async implementation of image processing and validation

        Args:
            input_data: download_results (list: result_segments)
            **kwargs: Additional parameters including 'context' with segments and other metadata

        Returns:
            Processed segment results with validated/replaced images

        Raises:
            ProcessingError: If image processing or validation fails
        """
        metric = self._start_processing(ProcessingStage.DOWNLOAD)
        try:
            download_results = input_data
            context = kwargs.get("context")
            temp_dir = context.temp_dir

            if not temp_dir:
                raise ProcessingError("temp_dir is required in context")

            if not context:
                raise ProcessingError("Context is required for ImageAutoProcessor")
            if not download_results:
                raise ProcessingError("Invalid download results format")

            result_segments = download_results
            # Check segment count matches asset count
            keywords = context.get("keywords")

            min_width = settings.video_min_image_width
            min_height = settings.video_min_image_height

            new_result_segments = []
            for segment in result_segments:
                # Ki·ªÉm tra video tr∆∞·ªõc, n·∫øu c√≥ video th√¨ valid = True lu√¥n
                video_obj = segment.get("video")
                if video_obj:
                    valid = True
                else:
                    # N·∫øu kh√¥ng c√≥ video, ki·ªÉm tra image
                    image_obj = segment.get("image", {})
                    image_path = image_obj.get("local_path")
                    valid = False
                    if image_path:
                        valid = is_image_size_valid(image_path, min_width, min_height)

                # T√°ch content v√† fields ƒë·ªÉ truy·ªÅn ri√™ng bi·ªát
                content = segment.get("voice_over", {}).get("content", "")
                fields = keywords  # keywords t·ª´ context

                merged_asset = segment.copy()
                # Ch·ªâ thay th·∫ø ·∫£nh n·∫øu kh√¥ng ph·∫£i video v√† ·∫£nh kh√¥ng h·ª£p l·ªá
                if not valid:
                    # T√¨m ki·∫øm v√† t·∫£i ·∫£nh m·ªõi
                    new_url, local_path = await self._download_image(
                        content=content, fields=fields, temp_dir=temp_dir
                    )

                    # C·∫≠p nh·∫≠t th√¥ng tin asset
                    if "image" in merged_asset and isinstance(
                        merged_asset["image"], dict
                    ):
                        merged_asset["image"]["url"] = new_url
                        merged_asset["image"]["local_path"] = local_path
                    else:
                        merged_asset["image"] = {
                            "url": new_url,
                            "local_path": local_path,
                        }

                new_result_segments.append(merged_asset)

            self._end_processing(
                metric, success=True, items_processed=len(new_result_segments)
            )
            return new_result_segments

        except Exception as e:
            self._end_processing(metric, success=False, error_message=str(e))
            raise ProcessingError(f"Image validation/search failed: {e}") from e
